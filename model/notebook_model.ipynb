{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8e3f7e",
   "metadata": {},
   "source": [
    "# Librairy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b2b5fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ecbb3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Titanic.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60b921",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7fa6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'alone']]\n",
    "target = df['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline pour les variables numériques\n",
    "numeric_features = ['age', 'sibsp', 'parch', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline pour les variables catégorielles\n",
    "categorical_features = ['sex', 'embarked', 'class', 'who', 'alone']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinaison des transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64138bb8",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1de2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6749a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__gamma': [1, 0.1, 0.01],\n",
    "        'classifier__kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('azureml://<workspace_url>')\n",
    "mlflow.set_experiment('Titanic_Survival_Prediction_Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f059fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84548eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', models[model_name])\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grids[model_name], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "    print(f\"Best cross-validation accuracy for {model_name}: {best_score}\")\n",
    "\n",
    "    # Évaluer les meilleurs modèles sur le jeu de test\n",
    "    y_pred = best_models[model_name].predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test accuracy for {model_name}: {test_accuracy}\")\n",
    "    print(f\"Classification report for {model_name}:\\n {classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    # Enregistrer les résultats\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Parameters': best_params,\n",
    "        'Cross-validation Accuracy': best_score,\n",
    "        'Test Accuracy': test_accuracy\n",
    "    })\n",
    "    \n",
    "    # Utilisation de MLFlow pour suivre les modèles\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.sklearn.log_model(best_models[model_name], model_name)\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric('cv_accuracy', best_score)\n",
    "        mlflow.log_metric('test_accuracy', test_accuracy)\n",
    "        print(f\"Logged {model_name} to MLFlow with test accuracy: {test_accuracy}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9951f82",
   "metadata": {},
   "source": [
    "# ML Flow configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c839d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('azureml://<workspace_url>')\n",
    "mlflow.set_experiment('Titanic_Survival_Prediction')\n",
    "\n",
    "# Démarrer une nouvelle exécution MLFlow\n",
    "with mlflow.start_run():\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "    mlflow.tensorflow.log_model(model, 'model')\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    mlflow.log_metric('loss', loss)\n",
    "    mlflow.log_metric('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ecf2c5",
   "metadata": {},
   "source": [
    "# Azure deploiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Se connecter à l'espace de travail Azure ML\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Enregistrer le modèle dans Azure ML\n",
    "model = Model.register(workspace=ws, model_name='titanic_survival_model', model_path='path/to/model')\n",
    "\n",
    "# Créer l'environnement pour l'inférence\n",
    "env = Environment(name='titanic-env')\n",
    "python_packages = ['tensorflow', 'scikit-learn', 'pandas']\n",
    "for package in python_packages:\n",
    "    env.python.conda_dependencies.add_pip_package(package)\n",
    "\n",
    "# Configurer l'inférence\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=env)\n",
    "\n",
    "# Configurer le déploiement\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Déployer le service web\n",
    "service = Model.deploy(workspace=ws, name='titanic-survival-service', models=[model], inference_config=inference_config, deployment_config=aci_config)\n",
    "service.wait_for_deployment(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b6593",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10292215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path('titanic_survival_model')\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    predictions = model.predict(data)\n",
    "    return json.dumps(predictions.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c27fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__gamma': [1, 0.1, 0.01],\n",
    "        'classifier__kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Définir l'URI de suivi MLFlow\n",
    "mlflow.set_tracking_uri('azureml://<workspace_url>')\n",
    "mlflow.set_experiment('Titanic_Survival_Prediction_Comparison')\n",
    "\n",
    "# Itérer sur les modèles et effectuer GridSearchCV\n",
    "best_models = {}\n",
    "results = []\n",
    "\n",
    "for model_name in models:\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', models[model_name])\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grids[model_name], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "    print(f\"Best cross-validation accuracy for {model_name}: {best_score}\")\n",
    "\n",
    "    # Évaluer les meilleurs modèles sur le jeu de test\n",
    "    y_pred = best_models[model_name].predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test accuracy for {model_name}: {test_accuracy}\")\n",
    "    print(f\"Classification report for {model_name}:\\n {classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    # Enregistrer les résultats\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Parameters': best_params,\n",
    "        'Cross-validation Accuracy': best_score,\n",
    "        'Test Accuracy': test_accuracy\n",
    "    })\n",
    "    \n",
    "    # Utilisation de MLFlow pour suivre les modèles\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.sklearn.log_model(best_models[model_name], model_name)\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric('cv_accuracy', best_score)\n",
    "        mlflow.log_metric('test_accuracy', test_accuracy)\n",
    "        print(f\"Logged {model_name} to MLFlow with test accuracy: {test_accuracy}\")\n",
    "\n",
    "# Afficher les résultats détaillés\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
